{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e8e29f-0523-4be0-a8d2-519b244d47fb",
   "metadata": {},
   "source": [
    "# LLM foundation in pictures\n",
    "\n",
    "Source [course](https://learn.deeplearning.ai/courses/how-transformer-llms-work/lesson/1/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ff458-7bfa-4041-bb8a-be2f7c4f432a",
   "metadata": {},
   "source": [
    "<img width=\"800px\" src=\"./img/106265.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e0e4ba-709e-442d-b8de-9c80502cfe38",
   "metadata": {},
   "source": [
    "Transformers (Encoders/Decoders) - The meaning of the words is captured from the context of the sentence or paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e0ed83-5b44-465f-8aea-262d27c8b7df",
   "metadata": {},
   "source": [
    "## Bag of Words (BOW)\n",
    "\n",
    "BOW - An algorithm that represents the words as large sparse vectors.\n",
    "\n",
    "BOW is simple method that doesn't consider the semantic nature of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c6909-f6af-46e7-af5e-a8829fbaa5d5",
   "metadata": {},
   "source": [
    "<img width=\"800px\" src=\"./img/238302.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0e9b3-862a-4f68-af7e-e15d00d79393",
   "metadata": {},
   "source": [
    "<img width=\"800px\" src=\"./img/312333.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1911bc-53e2-4cb4-a1b2-fa33f8efd7ff",
   "metadata": {},
   "source": [
    "## Word2Vec (vector embeddings)\n",
    "\n",
    "Word2Vec - The word representation that captures the meaning of the words in the context of the neighboring words by leveraging neural nets.\n",
    "\n",
    "These are STATIC embeddings that represent the word without context, i.e. word \"bank\" depending on the context could be either a financial institution or a river."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a64f38-6cb3-4803-b92a-0c7b767ebd07",
   "metadata": {},
   "source": [
    "<img width=\"800px\" src=\"./img/61268.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13bed9-f409-4fa8-84a0-ad6f91dec9c8",
   "metadata": {},
   "source": [
    "<img width=\"800px\" src=\"./img/106080.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1e9299-295f-486d-9867-e7878333ad5e",
   "metadata": {},
   "source": [
    "The properties of the words are the dimentions of embedding vector space. \n",
    "\n",
    "<img width=\"800px\" src=\"./img/169703.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca8a44-55e4-4a61-86de-d5f1461958b8",
   "metadata": {},
   "source": [
    "In fact it is not possible to define what exact property each dimention represents. Instead it can be derived from 2d-plot.\n",
    "\n",
    "<img width=\"800px\" src=\"./img/200727.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58219e4f-4316-4765-bd74-35476613eaa6",
   "metadata": {},
   "source": [
    "## Types of embeddings\n",
    "\n",
    "* Words\n",
    "\n",
    "* Sentence\n",
    "\n",
    "* Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44fda51-20f7-4673-97ac-d1b2f3d16dba",
   "metadata": {},
   "source": [
    "Word2Vec is a **representation model** as it attempts to represent text as values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796d49c-3f61-4115-9ee4-76c0a9f866d6",
   "metadata": {},
   "source": [
    "<img width=\"800px\" src=\"./img/288798.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b13224-5945-4e03-8774-31f0d3b74da6",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c015b1-24e9-4f1e-9faf-3667ff024f3d",
   "metadata": {},
   "source": [
    "RNN is able to generate a whole sentence.\n",
    "\n",
    "<img width=\"800px\" src=\"./img/86201.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f800b4b-45b1-4fd1-a96c-2d48169b638c",
   "metadata": {},
   "source": [
    "Each step of generating a token (word) is autoregressive.\n",
    "\n",
    "The input and previously generated tokens are requiered for next token generation. \n",
    "\n",
    "Most models are autoregressive and therefore generate a single token each time.\n",
    "\n",
    "<img width=\"800px\" src=\"./img/134929.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652b465e-a855-46c2-acd9-3fa604402686",
   "metadata": {},
   "source": [
    "RNN encoder takes one sequence and processes it in one go, generating a \"context embedding\". \n",
    "\n",
    "With a single context embedding, it makes difficult to deal with longer or more complex sequences.\n",
    "\n",
    "<img width=\"800px\" src=\"./img/212093.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b3b5b-ca51-4833-b9e6-dbbddc04c8ca",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e8019-ce9b-43ad-9812-a2556fbeb6ff",
   "metadata": {},
   "source": [
    "A better approach is an attention mechanism, that allows to \"focus\" on more relevant tokens.\n",
    "\n",
    "<img width=\"800px\" src=\"./img/325240.png\" style=\"border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "</img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1049e8-442d-495b-b730-51b004ca61b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crds_dev_env_2-1_pymc]",
   "language": "python",
   "name": "conda-env-crds_dev_env_2-1_pymc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
